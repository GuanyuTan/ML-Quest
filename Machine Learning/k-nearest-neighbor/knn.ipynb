{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor\n",
    "\n",
    "KNN is can be used for both classification and regression.\n",
    "\n",
    "Intuition is we are using K nearest neightbors(hence the name) to aid us in classifying or regressing our input of interest. How do we select the nearest neighbors? We decide by calculating the Minkowski Distance between out input data point and all the data. Then we select the top-k nearest instances.\n",
    "\n",
    "For classification, we aggregate the classes of the k nearest instances. The mode class will be the predicted class.\n",
    "\n",
    "For regression, we take the mean of the attribute of interes of the k nearest instances and that will be our prediction.\n",
    "\n",
    "While its simplicity, KNN face difficulties doing inference when a large amount of training data is used. This is due to the requirement of computing the relative distance array for each data point.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data = load_iris()\n",
    "x = data['data']\n",
    "y = data['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a whole:\n",
    "1. Calculate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier():\n",
    "    def __init__(self, k, regression=False):\n",
    "        self.k = k\n",
    "        self.regression = regression\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        assert x.shape[0] == y.shape[0], 'Number of data points in x is not the same as that in y'\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "\n",
    "    def MinkowskiDistance(self, x, z, p):\n",
    "        \"\"\"\n",
    "        Compute distance matrix\n",
    "        \"\"\"\n",
    "        return np.power(np.sum(np.power(np.abs(np.tile(x,(z.shape[0])).reshape(x.shape[0],z.shape[0],z.shape[-1])-z),p), axis=-1),1/p)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if len(x.shape)==2:\n",
    "            distances=self.MinkowskiDistance(x, self.data, 2)\n",
    "            indices = np.argsort(np.array(distances))\n",
    "            labels = self.labels[indices[:,:10]]\n",
    "            if self.regression:\n",
    "                return(np.mean(labels))\n",
    "            else:\n",
    "                res = []\n",
    "                for li in labels:\n",
    "                    unique, counts = np.unique(li, return_counts=True)\n",
    "                    res.append(unique[np.argmax(counts)])\n",
    "                return np.array(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = KNNClassifier(k=10)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn example\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X=x_train, y=y_train)\n",
    "out = knn.predict(x_test)\n",
    "print(classification_report(y_test, out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
